# -*- coding: utf-8 -*-
"""classification with spark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SvxzBPa5_oHZ1_dFKzpBgZQTJVOOoRfm

# Import necessary libraries
"""

from pyspark.sql import SparkSession  #creates the entry point for interacting with a Spark cluster.
from pyspark.ml.feature import Tokenizer   #for the text processing steps, like converting text into numerical features.
from pyspark.ml.feature import StopWordsRemover
from pyspark.ml.feature import HashingTF, IDF
from pyspark.ml.classification import LogisticRegression  #imports the specific machine learning algorithm you'll use.
from pyspark.ml import Pipeline   #allows you to chain all the steps together into a single workflow.
from pyspark.ml.evaluation import MulticlassClassificationEvaluator  #evaluating the performance of your model.

"""# Load dataset"""

spark = SparkSession.builder.appName("EmotionClassifier").getOrCreate()   #creates a Spark session named "EmotionClassifier"
df = spark.read.csv("emotions.csv", header=True, inferSchema=True)
df.show(5)

"""# Select only the needed column and remove rows with null values"""

df = df.select("text", "label").na.drop()

"""# Spark ML pipeline steps"""

tokenizer = Tokenizer(inputCol="text", outputCol="words")

remover = StopWordsRemover(inputCol="words", outputCol="filtered")

hashingTF = HashingTF(inputCol="filtered", outputCol="rawFeatures", numFeatures=10000)
idf = IDF(inputCol="rawFeatures", outputCol="features")

"""# ML classification and Training"""

lr = LogisticRegression(featuresCol="features", labelCol="label")

pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])   #define pipeline

train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)   #split data
model = pipeline.fit(train_df)     #train the model
predictions = model.transform(test_df)  #make predictions
predictions.select("text","label","prediction").show(10)

evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
print(f"Accuracy: {accuracy:.2f}")